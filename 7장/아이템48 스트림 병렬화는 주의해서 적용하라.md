# 아이템48. 스트림 병렬화는 주의해서 적용하라

자바는 항상 동시성 프로그래밍을 생각했다.

## 🧵 자바 초기 (스레드, 동기화, wait/notify)

- **Thread 클래스 / Runnable 인터페이스**
    
    → 개발자가 직접 스레드를 만들고 실행(`start()`)시켜야 했음.
    
- **synchronized 키워드**
    
    → 공유 자원에 여러 스레드가 접근할 때 충돌을 막기 위해 사용.
    
- **wait()/notify()/notifyAll()** (Object 메서드)
    
    → 스레드 간 협업(Producer-Consumer 문제 등)을 위해 제공.
    
    단점:
    
    - 저수준(Low-level) API라 코드 복잡도 ↑
    - 직접 락(lock) 관리 → 오류 발생 가능성 ↑

## ⚙️ 자바 5 (java.util.concurrent, Executor 프레임워크)

- **java.util.concurrent 패키지 도입**
    
    → 고수준의 동시성 API 제공, 직접 스레드 제어하지 않아도 됨.
    
- 주요 기능:
    - **Executor / ExecutorService**: 스레드 풀(Thread Pool) 기반 실행 관리
        
        ```java
        ExecutorService pool = Executors.newFixedThreadPool(10);
        pool.submit(() -> { /* 작업 코드 */ });
        
        ```
        
    - **Future / Callable**: 결과를 반환하는 비동기 작업
    - **동시성 컬렉션**: ConcurrentHashMap, BlockingQueue 등
    - **Lock, Semaphore, CountDownLatch, CyclicBarrier** 등 다양한 동기화 도구
- 장점:
    - "스레드를 직접 다루지 않고 **작업 단위(Task)** 중심 프로그래밍 가능"

## ⚡ 자바 7 (Fork-Join 프레임워크)

- **Fork/Join Framework** (`java.util.concurrent.ForkJoinPool`)
    
    → 큰 작업을 작은 단위로 **재귀적으로 분할(Fork)** 후, 결과를 합치는(Join) 방식.
    
- **Work-stealing 알고리즘** 사용
    
    → 놀고 있는 스레드가 다른 스레드의 작업을 훔쳐와서 처리 → CPU 활용 극대화.
    
- 활용 예:
    - 배열 합계, 대용량 데이터 처리, 재귀적 분할 정복 알고리즘
    
    ```java
    class SumTask extends RecursiveTask<Long> {
        long[] arr; int start, end;
        protected Long compute() {
            if (end - start <= 1000) { // 작은 작업은 직접 계산
                long sum = 0;
                for (int i = start; i < end; i++) sum += arr[i];
                return sum;
            }
            int mid = (start + end) / 2;
            SumTask left = new SumTask(arr, start, mid);
            SumTask right = new SumTask(arr, mid, end);
            left.fork(); // 왼쪽 분할
            return right.compute() + left.join(); // 오른쪽 계산 + 왼쪽 결과
        }
    }
    
    ```
    
- 장점:
    - **병렬 처리 최적화** (특히 멀티코어 CPU 환경)

## 🌊 자바 8 (Parallel Streams)

- **Stream API** 도입 + `parallelStream()`
    
    → 데이터 처리 파이프라인을 선언적으로 작성, 내부적으로 ForkJoinPool 사용.
    
- 예시:
    
    ```java
    List<Integer> nums = Arrays.asList(1,2,3,4,5,6,7,8,9);
    int sum = nums.parallelStream()
                  .mapToInt(i -> i * 2)
                  .sum();
    
    ```
    
- 특징:
    - 개발자는 **병렬 처리 로직을 직접 작성하지 않아도 됨**
    - 내부적으로 Fork-Join 풀을 사용해 자동 병렬화
- 주의점:
    - 무조건 빠른 게 아님 (작업 크기, 데이터량, CPU 코어 수에 따라 성능 달라짐)
    - 순서 보장이 중요한 경우 `parallel()`은 피하는 게 좋음.

```java
public static void main(String[] args) {
    primes()
        .map(p -> TWO.pow(p.intValueExact()).subtract(ONE))
        .filter(mersenne -> mersenne.isProbablePrime(50))
        .limit(20)
        .forEach(System.out::println);
}

static Stream<BigInteger> primes() {
    return Stream.iterate(TWO, BigInteger::nextProbablePrime);
}
```

🎯 문제점

1. iterate

### 스트림 병렬화 성능 = "데이터 쪼개기(splitting)" 가능성

병렬 스트림은 내부적으로 **Fork/Join 프레임워크**를 씁니다.

- 전체 데이터를 **쪼개서 여러 코어에 분산** → 처리 → 결과 합치기
- 예: `ArrayList`는 랜덤 액세스가 가능하니 `[0..499]`, `[500..999]` 이런 식으로 반씩 쪼개기가 쉬움 → 병렬 효과 좋음
- 반대로 **쪼개기 어려운 데이터 구조**는 병렬화해도 스레드 간 부하 분산이 안 됨.

---

### 2. `Stream.iterate`의 문제

- `iterate(seed, f)`는 **"앞 원소를 알아야 다음 원소를 알 수 있는"** 구조예요.
    
    예: `2 → 3 → 5 → 7 …` 이런 식으로 순차적으로만 만들어낼 수 있음.
    
- 즉, **"100번째 원소"를 바로 알 수 없음**.
    - `ArrayList.get(100)`은 O(1)이지만,
    - `iterate`는 처음부터 100번 반복 호출해야 100번째 원소가 나옴.
- 그러니 Fork/Join이 **중간을 잘라서 분할(splitting)** 하는 게 사실상 불가능함.

---

### 3. 그 결과

- 병렬 스트림에서 `iterate`는 전체를 **순차적으로 만들어낸 뒤** 그걸 다시 나눠야 하므로
    
    → 병렬 효과가 거의 없음
    
    → 오히려 쓰레드 컨텍스트 스위칭 등 부가비용 때문에 더 느려짐.
    

2.limit

- **정렬된 스트림(`ordered` stream)**
    - `limit(n)`을 만나면 순서를 지켜야 해서, 내부적으로 더 많은 원소를 처리하고도 버릴 가능성이 큼.
    - 따라서 병렬 효과가 줄어듦.
- **비정렬 스트림(`unordered` stream)**
    - 순서를 지킬 필요가 없으니, 병렬에서 `limit(n)`을 만나도 효율적으로 "아무 n개"만 뽑아옴.
    - 성능이 더 좋을 수 있음.

# 그래서!!!!

ArrayList, HashMap, HashSet,,,, int 범위, long 범위일 때 병렬화의 효과가 가장 좋다

## 왜 효과가 좋은가

1. **크기·경계가 딱 정해짐 (SIZED/SUBSIZED)**
    - `ArrayList`, `HashMap`, `HashSet`, `IntStream.range`, `LongStream.range`는 **원소 수를 정확히 알고** 있고, 반으로 **깔끔하게 분할**할 수 있어요.
    - 스트림 내부의 `Spliterator`가 `SIZED`(총 크기 앎), `SUBSIZED`(나뉜 조각도 크기 앎) 특성을 가져 **Fork/Join이 균형 있게 작업을 나누기** 쉬움.
2. **빠른 분할 비용 (O(1) ~ O(log n))**
    - `ArrayList`: 내부가 연속 인덱스라 **[lo, mid) / [mid, hi)** 범위로 즉시 쪼갬(랜덤 액세스).
    - `HashMap/HashSet`: 해시 테이블 버킷/배열을 **구간 단위로 나눠** 전달 가능.
    - `IntStream.range/LongStream.range`: **수학적 구간**을 그대로 **하위 구간**으로 쪼개면 끝(가장 이상적).
3. **작업량이 균질**
    - 각 원소 처리 비용이 비슷하다는 가정하에, 조각을 나누기만 해도 **부하가 코어들 사이에 고르게 분산**됨.
    - 반대로 `iterate`/`generate`, I/O 스트림처럼 원소 생성 비용이 들쭉날쭉하면 균형이 깨짐.
4. **메모리 지역성 / 낮은 오버헤드**
    - `ArrayList`는 연속 메모리라 **캐시 친화적**.
    - `IntStream.range/LongStream.range`는 **박싱이 없는(primitive) 스트림**이라 오토박싱 비용이 없음 → 병렬화 이득이 더 잘 드러남.
        - 박싱이란?
            
            ```java
            List<Integer> list = new ArrayList<>();
            list.add(5);   // int → Integer.valueOf(5) 자동 삽입
            
            Integer x = 10; // 자동 박싱
            int y = x;      // 자동 언박싱 (x.intValue() 호출)
            ```
            
5. **순서 제약이 적거나 다루기 쉬움**
    - `HashSet/HashMap`은 본질적으로 **unordered**여서, `limit`, `skip` 같은 순서 의존 단축연산이 없으면 병렬 최적화가 쉬움.
    - `ArrayList`는 ordered지만, **인덱스 범위 분할**이 너무 쉬워서 비용이 낮음.
    - `range`류는 순서가 있어도 **구간 분할이 완벽**해 성능이 잘 나옴.
6. **결과 결합(리듀스/컬렉트)이 자연스러움**
    - 병렬 리듀스는 **결합법칙(associative)** 이 중요해요. 합/최댓값/카운트/그룹핑 등은 **부분 결과를 합치기**가 쉬워 병렬 이득이 큼.
    - `Collectors.toList()`도 소스가 잘 분할되면 각 조각에서 리스트를 만들고 **마지막에 이어 붙이기**가 수월.

# 자바 Stream API가 올바르게 동작하기 위해 지켜야 할 세 가지 규칙

## 1. **결합 법칙(Associativity) 만족**

- `reduce()` 연산은 여러 조각에서 부분 결과를 만든 뒤 **병렬로 합쳐야** 하므로, **결합법칙(associative law)** 을 반드시 지켜야 해요.
- 결합법칙:
    
    ```
    (a ⊕ b) ⊕ c == a ⊕ (b ⊕ c)
    ```
    
- 즉, 연산 순서가 달라져도 결과가 같아야 합니다.
- 예시:
    - ✅ `+`, , `min`, `max` 등은 결합법칙 만족 → 병렬 처리 OK
    - ❌ 뺄셈(-), 나눗셈(/), 문자열 붙이기 순서가 중요한 경우 → 병렬 reduce에서 잘못된 결과 가능

---

## 2. **간섭받지 않아야 함 (Non-interference)**

- 스트림 파이프라인이 실행되는 동안 **데이터 소스(Collection 등)** 가 **외부에서 변경되면 안 됨**.
- 왜냐면:
    - 스트림은 lazy하게 동작해서, `map`, `filter`가 당장 실행되지 않고 최종 연산 시점에 평가됨.
    - 중간에 원본 데이터가 바뀌면, 스트림이 예상치 못한 데이터 상태를 읽게 됨.
- 예시:
    
    ```java
    List<String> list = new ArrayList<>(List.of("a", "b", "c"));
    Stream<String> s = list.stream();
    list.add("d");   // ⚠ 스트림 생성 후 리스트 변경
    s.forEach(System.out::println); // Undefined Behavior
    ```
    
- → 스트림 실행 중에는 원본 소스를 절대 변경하면 안 됨.

---

## 3. **상태(state)를 갖지 않아야 함 (Statelessness)**

- 스트림의 중간 연산자(map, filter, etc.)는 **입력 값에만 의존**해야 하고, 외부 가변 상태에 의존해서는 안 됨.
- 왜냐면:
    - 병렬 실행 시 여러 스레드가 동시에 접근할 수 있는데, 외부 상태를 공유하면 동시성 문제가 생김.
- 잘못된 예:
    
    ```java
    List<Integer> numbers = List.of(1, 2, 3, 4, 5);
    int[] sum = {0};
    
    numbers.stream().map(n -> {
        sum[0] += n; // 외부 상태(sum)에 누적 (⚠ 상태 의존 + 변경)
        return n;
    }).forEach(System.out::println);
    
    System.out.println("합계: " + sum[0]);
    ```
    
    병렬 스트림일 경우 레이스 컨디션 발생 가능.
    
    ```java
    numbers.parallelStream().map(n -> { sum[0] += n; return n; })
    ```
    
- 올바른 방법:
    
    ```java
    int total = numbers.stream()
                       .mapToInt(n -> n)   // 입력만 쓰고 외부 상태 건드리지 않음
                       .sum();             // 최종 연산에서 안전하게 합산
    ```
    

# 무작위 수들로 이뤄진 스트림을 병렬화하려거든 SplittableRandom 인스턴스를 이용하자

## 🔎 왜 Random, ThreadLocalRandom은 병렬 스트림에 안 맞을까?

### 1. `java.util.Random`

- 내부적으로 **하나의 `AtomicLong seed` 필드**를 갖고 있어요.
- `nextInt()`, `nextLong()` 호출할 때마다 `CAS`(compare-and-swap)로 이 seed를 갱신.
- 즉, 여러 스레드가 동시에 쓰면 → **경합(contention)** 발생 → 병렬 처리 성능 급락.

---

### 2. `java.util.concurrent.ThreadLocalRandom`

- `Random`의 경합 문제를 개선하기 위해 나온 클래스.
- 스레드마다 **독립된 난수 발생기**를 가짐.
- 그래서 멀티스레드 환경에서 `Random`보다 훨씬 빠름.

⚠️ 하지만…

- **SplittableRandom처럼 "쪼개져서 분할(fork)되는 특성"은 없음.**
- 즉, 병렬 스트림이 `ForkJoinPool` 기반으로 데이터 소스를 **반으로 쪼개며(split)** 작업을 나누는데,
    
    ThreadLocalRandom은 이런 분할 패턴에 최적화되어 있지 않음.
    

---

## 🔎 SplittableRandom의 특수한 설계

- **자바 8부터 도입된 난수 발생기.**
- 이름처럼 **splittable(쪼갤 수 있는)** 구조.
- `SplittableRandom` 인스턴스는 `split()` 메서드를 통해 **독립된 새 난수 발생기를 O(1)로 생성**할 수 있음.
- 그래서 병렬 스트림에서 데이터 분할이 일어날 때, 난수 발생기도 같이 **분할·복제되어 각 스레드에 안전하게 전달**됨.

👉 결과:

- 스레드 간 경합이 아예 없음.
- 병렬화 스케일이 코어 수에 맞춰 **선형적으로 증가**할 수 있음.
    
    (스레드 2개 → 2배, 4개 → 4배, …)